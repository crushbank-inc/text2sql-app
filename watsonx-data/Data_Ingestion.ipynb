{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88af501b-729d-4596-9640-da470210f126",
   "metadata": {},
   "source": [
    "![Top <](./images/watsonxdata.png \"watsonxdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6556fca-c4eb-4e1a-a671-edc775339326",
   "metadata": {},
   "source": [
    "# Data Ingestion through Spark\n",
    "This notebook demonstrate how Spark can connect to watsonx.data and ingest the data. This system has a local Spark engine that will be used to access watsonx.data. This is a minimally configured Spark engine, but is sufficient to demonstrate the steps needed to connect to watsonx.data and access the data that resides in the catalogs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fbd8a-e091-40ce-bda4-a75939ffa7a3",
   "metadata": {},
   "source": [
    "## Copy Spark Libraries\n",
    "The Spark libraries that are used by this notebook need to be loaded into the local file system in order for the spark calls to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957e9eb4-dc34-4e92-ab53-bf346e1268fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system tar -xf /spark/spark.tgz -C /usr/local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c914e9-b25f-4c73-bd67-8f88bdff8b78",
   "metadata": {},
   "source": [
    "## Environment Variables \n",
    "We need to make sure that a number of environment variables are set so that the Spark code can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f16915d-8856-45f4-87c0-81d217e693ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/usr/local/spark\n",
      "env: PYSPARK_DRIVER_PYTHON=jupyter\n",
      "env: PYSPARK_DRIVER_PYTHON_OPTS=notebook\n",
      "env: PATH=/usr/local/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/root/bin\n"
     ]
    }
   ],
   "source": [
    "%env SPARK_HOME=/usr/local/spark\n",
    "%env PYSPARK_DRIVER_PYTHON=jupyter\n",
    "%env PYSPARK_DRIVER_PYTHON_OPTS=notebook\n",
    "%env PATH=/usr/local/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/spark/bin:/root/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f8dbc-1136-44d1-91df-cab3e4281c75",
   "metadata": {},
   "source": [
    "## System Variables\n",
    "In addition to the environment variables, we need to set some Python variables that will be used throughout the scripts. These settings are:\n",
    "* minio_host - The URL of the Minio server\n",
    "* minio_port - The port that the Minio server is using\n",
    "* hive_host  - The URL of the Thrift/Hive server\n",
    "* hive_port  - The port that the Thrift/Hive server is using\n",
    "\n",
    "Note that the URLs and PORTS are for an internal connection in the watsonx.data development server. These URLs and PORTS will be different if you are connecting externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43f1d359-31ac-4989-802f-60ea9af77f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_host    = \"watsonxdata\"\n",
    "minio_port    = \"9000\"\n",
    "hive_host     = \"watsonxdata\"\n",
    "hive_port     = \"8380\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfd3f2-989e-4685-b82f-ce8a8ad765a4",
   "metadata": {},
   "source": [
    "## Minio - Object Storage CLI\n",
    "In order to use the MinIO CLI, we must first register the MinIO server that we need to connect to. Before we do that we need to extract the passwords of the MinIO service, along with some other credentials. The passwords for all of the services can be found in the `/certs/passwords` file found in this server. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63114429-4ee3-4695-84bd-61f1de7162a6",
   "metadata": {},
   "source": [
    "The following code will extract all of the passwords and userids that are required for the MinIO and Spark connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aadd417f-c215-41ae-90f3-85458bf4f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_id           = None\n",
    "hive_password     = None\n",
    "minio_access_key  = None\n",
    "minio_secret_key  = None\n",
    "keystore_password = None \n",
    "cert_file         = \"/certs/lh-ssl-ts.jks\"\n",
    "\n",
    "try:\n",
    "    with open('/certs/passwords') as fd:\n",
    "        certs = fd.readlines()\n",
    "    for line in certs:\n",
    "        args = line.split()\n",
    "        if (len(args) >= 3):\n",
    "            system   = args[0].strip()\n",
    "            user     = args[1].strip()\n",
    "            password = args[2].strip()\n",
    "            if (system == \"Minio\"):\n",
    "                minio_access_key = user\n",
    "                minio_secret_key = password\n",
    "            elif (system == \"Thrift\"):\n",
    "                hive_id = user\n",
    "                hive_password = password\n",
    "            elif (system == \"Keystore\"):\n",
    "                keystore_password = password\n",
    "            else:\n",
    "                pass\n",
    "except Error as e:\n",
    "    print(\"Certificate file with passwords could not be found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb878343-0259-493f-87fb-b15789a0a18b",
   "metadata": {},
   "source": [
    "### Minio - Objest Storage System Alias\n",
    "Before running any commands against the MinIO server, an alias needs to be created that includes the access and secret key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df42b03f-98d3-40be-9097-d53377ff5d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Added `watsonxdata` successfully.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system mc alias set watsonxdata http://{minio_host}:{minio_port} {minio_access_key} {minio_secret_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80874e9-94f8-4921-9810-7b2e8cc79c38",
   "metadata": {},
   "source": [
    "### List Buckets\n",
    "The `mc` command provides us with a number of commands that allows us to manage buckets and files within them. The following command checks to see if the `staging-bucket` exists. This bucket is used for all of the Spark examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b840e906-5aa0-41fa-919c-29ea0ec252b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[2024-12-17 15:12:13 EST]     0B hive-bucket/',\n",
       " '[2024-12-17 15:12:13 EST]     0B iceberg-bucket/',\n",
       " '[2025-01-15 23:57:45 EST]     0B staging-bucket/',\n",
       " '[2024-12-17 15:12:14 EST]     0B wxd-milvus/',\n",
       " '[2024-12-17 15:12:13 EST]     0B wxd-system/']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system mc ls tree watsonxdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f643c6-4fe1-45cd-8868-a28990178743",
   "metadata": {},
   "source": [
    "If the staging bucket exists, we will delete the bucket and the contents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4244b-5457-4de9-b04a-f508d255a2a2",
   "metadata": {},
   "source": [
    "### Create a Bucket\n",
    "At this point we will create the staging bucket that we are doing to use to hold our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "045fcdb5-c3c4-4570-a267-5e1c1283a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%system mc mb watsonxdata/staging-bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e77034d-83e5-4534-8c79-f3f4dfab8a07",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Next we will load the data from the `/staging-bucket` directory. Note that we need to use the full name of the bucket. The `mc` command allows to select which files to place into a bucket, or an entire directory with recursion. In this case we are only going to select the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ae48e0a-c197-4693-ac1c-944c71494650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%system mc cp /notebooks/staging-bucket/*.json watsonxdata/staging-bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695f230-20c8-4bd3-b690-868d0af6926b",
   "metadata": {},
   "source": [
    "We can double check that our files are there with the `mc ls tree` command and using the `--files` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c664d0-837d-4cc6-8cdc-f25693eef53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['watsonxdata/staging-bucket/',\n",
       " '├─ config_udfs.json',\n",
       " '├─ configs.json',\n",
       " '├─ contacts.json',\n",
       " '├─ tickets.json',\n",
       " '└─ time_entries.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system mc tree --files watsonxdata/staging-bucket/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968439a2-e5b6-4a41-952b-a998c418cc4b",
   "metadata": {},
   "source": [
    "# Spark Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436bd58-1b39-47ac-aa5b-a3749dc48d13",
   "metadata": {},
   "source": [
    "The next set of Python instructions will initialize the Spark connection. Once the connection is established to the engine, we need to update a number of values to provide credentials and a URL to the Hive and MinIO services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b709b62-daad-4999-8b2d-0654ff2bf5c6",
   "metadata": {},
   "source": [
    "### Initialize the Spark Connection\n",
    "Initialize the settings for the Spark service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9caa598-acfa-4fda-a9e2-1683ea40be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/23 01:59:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/23 01:59:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/01/23 01:59:14 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = SparkSession.builder.appName('sparky').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "conf = sc.getConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a036f-9866-4e82-8bb7-c3a967b1eee7",
   "metadata": {},
   "source": [
    "### Watsonx.data Configuration Information\n",
    "Once we have the configuration established, we need to update the values corresponding to our MinIO and Hive settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c32a8c10-dc0a-4fca-a768-b016dd0eb60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conf.set(\"spark.sql.debug.maxToStringFields\",                    \"100\")\n",
    "_ = conf.set(\"fs.s3a.path.style.access\",                             \"true\")\n",
    "_ = conf.set(\"fs.s3a.impl\",                                          \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "_ = conf.set(\"fs.s3a.connection.ssl.enabled\",                        \"true\")\n",
    "_ = conf.set(\"spark.driver.extraJavaOptions\",                        \"-Dcom.sun.jndi.ldap.object.disableEndpointIdentification=true\")\n",
    "\n",
    "_ = conf.set(\"spark.sql.catalogImplementation\",                      \"hive\")\n",
    "_ = conf.set(\"spark.sql.extensions\",                                 \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "_ = conf.set(\"spark.sql.iceberg.vectorization.enabled\",              \"false\")\n",
    "\n",
    "_ = conf.set(\"spark.sql.defaultCatalog\",                             \"iceberg_data\")\n",
    "_ = conf.set(\"spark.sql.catalog.iceberg_data\",                       \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "_ = conf.set(\"spark.sql.catalog.iceberg_data.type\",                  \"hive\")\n",
    "_ = conf.set(\"spark.sql.catalog.iceberg_data.uri\",                   f\"thrift://{hive_host}:{hive_port}\")\n",
    "\n",
    "_ = conf.set(\"spark.hive.metastore.client.auth.mode\",                \"PLAIN\")\n",
    "_ = conf.set(\"spark.hive.metastore.client.plain.username\",           hive_id)\n",
    "_ = conf.set(\"spark.hive.metastore.client.plain.password\",           hive_password)\n",
    "\n",
    "_ = conf.set(\"spark.hive.metastore.use.SSL\",                         \"true\")\n",
    "_ = conf.set(\"spark.hive.metastore.truststore.type\",                 \"jks\")\n",
    "_ = conf.set(\"spark.hive.metastore.truststore.path\",                 cert_file)\n",
    "_ = conf.set(\"spark.hive.metastore.truststore.password\",             keystore_password)\n",
    "_ = conf.set(\"spark.hive.metastore.uris\",                            f\"thrift://{hive_host}:{hive_port}\")\n",
    "\n",
    "_ = conf.set(\"spark.hadoop.fs.s3a.endpoint\",                         f\"http://{minio_host}:{minio_port}\")\n",
    "_ = conf.set(\"spark.hadoop.fs.s3a.access.key\",                       minio_access_key)\n",
    "_ = conf.set(\"spark.hadoop.fs.s3a.secret.key\",                       minio_secret_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ef828-0042-45d2-b2f8-6679ab7524ac",
   "metadata": {},
   "source": [
    "### Restart Spark with new Configuration\n",
    "To make the configuration changes take effect, we need to stop the Spark services and recreate it with the new configuration information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7b6685-60a1-466e-b9be-8606e49d4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "conf = sc.getConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3657e54-c3c4-4810-9438-da14814ffd5b",
   "metadata": {},
   "source": [
    "# Data Ingestion to Staging area\n",
    "Steps involved \n",
    "1. Read JSON file with pre-definded schema into a data frame\n",
    "2. Load the data frame to staging table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba1ec4-ed34-4ebc-9a29-9db0fb55c3eb",
   "metadata": {},
   "source": [
    "### 1/5. Ingest data from file \"config_udfs.json\" to table \"iceberg_data.cb_di.config_udfs_stg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "340cab0a-bde4-44b1-b4aa-769f2123e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+----+-----+\n",
      "|identifier|return_type| key|value|\n",
      "+----------+-----------+----+-----+\n",
      "|     16707|   CwConfig|null| null|\n",
      "|     16719|   CwConfig|null| null|\n",
      "|     16717|   CwConfig|null| null|\n",
      "|     16702|   CwConfig|null| null|\n",
      "|     16718|   CwConfig|null| null|\n",
      "|     11464|   CwConfig|null| null|\n",
      "|     11386|   CwConfig|null| null|\n",
      "|     11388|   CwConfig|null| null|\n",
      "|     11394|   CwConfig|null| null|\n",
      "|     11402|   CwConfig|null| null|\n",
      "|     11410|   CwConfig|null| null|\n",
      "|     11416|   CwConfig|null| null|\n",
      "|     11406|   CwConfig|null| null|\n",
      "|     11422|   CwConfig|null| null|\n",
      "|     11428|   CwConfig|null| null|\n",
      "|     11414|   CwConfig|null| null|\n",
      "|     11418|   CwConfig|null| null|\n",
      "|     11432|   CwConfig|null| null|\n",
      "|     11438|   CwConfig|null| null|\n",
      "|     11436|   CwConfig|null| null|\n",
      "+----------+-----------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col, lit, explode, create_map\n",
    "\n",
    "\n",
    "# Define schema for known fields\n",
    "schema = StructType([\n",
    "    StructField(\"identifier\", StringType(), True),\n",
    "    StructField(\"return_type\", StringType(), True),\n",
    "    StructField(\"key\", StringType(), True),\n",
    "    StructField(\"value\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load JSON file\n",
    "json_file_path = \"staging-bucket/config_udfs.json\"  # Replace with your file path\n",
    "json_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(json_file_path)\n",
    "\n",
    "# Select and cast necessary columns matching the Iceberg table schema\n",
    "data_to_insert = json_df.select(\n",
    "    col(\"identifier\").cast(\"int\"),\n",
    "    col(\"return_type\"),\n",
    "    col(\"key\"),\n",
    "    col(\"value\")\n",
    ")\n",
    "\n",
    "data_to_insert.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "965d7bc2-e831-4331-aad0-4bd244de7e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Insert directly into the Iceberg table\n",
    "data_to_insert.writeTo(\"iceberg_data.cb_di.config_udfs_stg\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca0977-0c4a-4a90-96cf-3ece9951dda3",
   "metadata": {},
   "source": [
    "### 2/5. Ingest data from file \"tickets.json\" to table \"iceberg_data.cb_di.tickets_stg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b3e0e5d-42d3-4928-9751-f7f628d64d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- identifier: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- integration_type: string (nullable = true)\n",
      " |-- board_id: string (nullable = true)\n",
      " |-- board_name: string (nullable = true)\n",
      " |-- status_id: string (nullable = true)\n",
      " |-- status_name: string (nullable = true)\n",
      " |-- actual_hours: string (nullable = true)\n",
      " |-- concept: string (nullable = true)\n",
      " |-- updated_date: string (nullable = true)\n",
      " |-- updated_by: string (nullable = true)\n",
      " |-- integration_id: string (nullable = true)\n",
      " |-- parent_name: string (nullable = true)\n",
      " |-- company_id: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- created_by: string (nullable = true)\n",
      " |-- return_type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- sub_type: string (nullable = true)\n",
      " |-- item: string (nullable = true)\n",
      " |-- ticket_owner: string (nullable = true)\n",
      " |-- sla: string (nullable = true)\n",
      " |-- agreement: string (nullable = true)\n",
      " |-- predecessor: string (nullable = true)\n",
      " |-- estimated_start_date: string (nullable = true)\n",
      " |-- due_date: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- impact: string (nullable = true)\n",
      " |-- priority: string (nullable = true)\n",
      " |-- sla_status: string (nullable = true)\n",
      " |-- budget_hours: string (nullable = true)\n",
      " |-- opportunity: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- vcio: string (nullable = true)\n",
      " |-- account_tech: string (nullable = true)\n",
      " |-- assigned_by: string (nullable = true)\n",
      " |-- closed_by: string (nullable = true)\n",
      " |-- closed_date: string (nullable = true)\n",
      "\n",
      "+----------+-----------------------------------------------------------------------------------------------------------------------+----------------+--------+----------+---------+-----------+------------+-------+--------------------+----------+--------------+-----------------------------------------+----------+--------------------+----------+-----------+----+--------+----+------------+----+---------+-----------+--------------------+--------+--------+------+--------+----------+------------+-----------+------+----+------------+-----------+---------+-----------+\n",
      "|identifier|link                                                                                                                   |integration_type|board_id|board_name|status_id|status_name|actual_hours|concept|updated_date        |updated_by|integration_id|parent_name                              |company_id|created_date        |created_by|return_type|type|sub_type|item|ticket_owner|sla |agreement|predecessor|estimated_start_date|due_date|duration|impact|priority|sla_status|budget_hours|opportunity|source|vcio|account_tech|assigned_by|closed_by|closed_date|\n",
      "+----------+-----------------------------------------------------------------------------------------------------------------------+----------------+--------+----------+---------+-----------+------------+-------+--------------------+----------+--------------+-----------------------------------------+----------+--------------------+----------+-----------+----+--------+----+------------+----+---------+-----------+--------------------+--------+--------+------+--------+----------+------------+-----------+------+----+------------+-----------+---------+-----------+\n",
      "|1160678   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160678|ConnectWise     |43      |          |625      |           |0           |       |2018-12-13T20:34:26Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-13T20:19:07Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160683   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160683|ConnectWise     |43      |          |625      |           |0           |       |2018-12-14T16:20:29Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-13T20:33:57Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160693   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160693|ConnectWise     |27      |          |405      |           |0           |       |2018-12-13T22:16:54Z|mmcdonald |877           |Teldar Paper                             |312       |2018-12-13T20:58:57Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160701   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160701|ConnectWise     |3       |          |51       |           |0           |       |2022-08-17T14:42:04Z|CrushBank |877           |Pied Piper                               |312       |2018-12-13T21:11:34Z|dterrazas |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160705   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160705|ConnectWise     |43      |          |625      |           |0           |       |2018-12-13T21:29:08Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-13T21:24:15Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160709   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160709|ConnectWise     |43      |          |625      |           |0           |       |2018-12-13T21:47:32Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-13T21:29:54Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160715   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160715|ConnectWise     |1       |          |17       |           |0           |       |2019-01-04T16:14:25Z|SSiciliano|877           |Tyrell Corporation                       |312       |2018-12-13T21:40:38Z|asheikh   |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160180   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160180|ConnectWise     |3       |          |51       |           |0           |       |2022-08-17T14:41:49Z|CrushBank |877           |Lencore Acoustics Corp.                  |312       |2018-12-12T16:26:14Z|jwilliams |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160195   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160195|ConnectWise     |43      |          |625      |           |0           |       |2018-12-12T17:15:11Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-12T16:57:54Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160197   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160197|ConnectWise     |27      |          |405      |           |0           |       |2018-12-12T20:12:32Z|mmcdonald |877           |Teldar Paper                             |312       |2018-12-12T17:04:51Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160679   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160679|ConnectWise     |3       |          |51       |           |0           |       |2022-08-17T14:42:07Z|CrushBank |877           |Promos and Goods                         |312       |2018-12-13T20:20:20Z|LPusey    |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160681   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160681|ConnectWise     |43      |          |625      |           |0           |       |2018-12-13T21:03:03Z|rvanscoy  |877           |Teldar Paper                             |312       |2018-12-13T20:32:15Z|mmcdonald |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|1160684   |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=1160684|ConnectWise     |3       |          |51       |           |0           |       |2022-08-17T14:42:04Z|CrushBank |877           |JBS LTD                                  |312       |2018-12-13T20:40:31Z|LPusey    |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|250236    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=250236 |ConnectWise     |3       |          |51       |           |0           |       |2018-05-10T16:46:52Z|akhalid   |877           |Livingston, Gentry & Mishkin             |312       |2011-08-03T21:34:05Z|LCiulla   |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|250660    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=250660 |ConnectWise     |3       |          |51       |           |0           |       |2018-05-14T19:50:52Z|akhalid   |877           |Anacott Steel                            |312       |2011-08-05T20:38:52Z|dwoltjen  |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|250588    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=250588 |ConnectWise     |3       |          |51       |           |2           |       |2018-07-03T15:56:21Z|ELeonard  |877           |Metro Air Tech                           |312       |2011-08-05T12:49:16Z|dwoltjen  |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|252632    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=252632 |ConnectWise     |3       |          |51       |           |0           |       |2018-05-11T16:42:05Z|akhalid   |877           |JV Enterprise                            |312       |2011-08-08T15:29:48Z|mclark    |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|252826    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=252826 |ConnectWise     |3       |          |51       |           |0           |       |2018-05-11T20:55:12Z|akhalid   |877           |Anacott Steel                            |312       |2011-08-09T12:40:55Z|website   |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|961520    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=961520 |ConnectWise     |27      |          |405      |           |0           |       |2017-12-14T19:34:49Z|zAdmin    |877           |Teldar Paper                             |312       |2017-12-14T15:12:20Z|RRogers   |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "|961527    |https://staging.connectwisedev.com/v4_6_release/services/system_io/Service/fv_sr100_request.rails?service_recid=961527 |ConnectWise     |2       |          |52       |           |2           |       |2017-12-22T17:44:28Z|emcbride  |877           |Ear, Nose & Throat Associates of New York|312       |2017-12-14T15:22:31Z|Tsilva    |CwTicket   |    |        |    |            |null|         |           |                    |        |        |      |        |          |            |           |      |    |            |           |         |           |\n",
      "+----------+-----------------------------------------------------------------------------------------------------------------------+----------------+--------+----------+---------+-----------+------------+-------+--------------------+----------+--------------+-----------------------------------------+----------+--------------------+----------+-----------+----+--------+----+------------+----+---------+-----------+--------------------+--------+--------+------+--------+----------+------------+-----------+------+----+------------+-----------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define the schema with StringType for all columns\n",
    "schema = StructType([\n",
    "    StructField(\"identifier\", StringType(), True),\n",
    "    StructField(\"link\", StringType(), True),\n",
    "    StructField(\"integration_type\", StringType(), True),\n",
    "    StructField(\"board_id\", StringType(), True),\n",
    "    StructField(\"board_name\", StringType(), True),\n",
    "    StructField(\"status_id\", StringType(), True),\n",
    "    StructField(\"status_name\", StringType(), True),\n",
    "    StructField(\"actual_hours\", StringType(), True),\n",
    "    StructField(\"concept\", StringType(), True),\n",
    "    StructField(\"updated_date\", StringType(), True),\n",
    "    StructField(\"updated_by\", StringType(), True),\n",
    "    StructField(\"integration_id\", StringType(), True),\n",
    "    StructField(\"parent_name\", StringType(), True),\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"created_date\", StringType(), True),\n",
    "    StructField(\"created_by\", StringType(), True),\n",
    "    StructField(\"return_type\", StringType(), True),\n",
    "    StructField(\"type\", StringType(), True),\n",
    "    StructField(\"sub_type\", StringType(), True),\n",
    "    StructField(\"item\", StringType(), True),\n",
    "    StructField(\"ticket_owner\", StringType(), True),\n",
    "    StructField(\"sla\", StringType(), True),\n",
    "    StructField(\"agreement\", StringType(), True),\n",
    "    StructField(\"predecessor\", StringType(), True),\n",
    "    StructField(\"estimated_start_date\", StringType(), True),\n",
    "    StructField(\"due_date\", StringType(), True),\n",
    "    StructField(\"duration\", StringType(), True),\n",
    "    StructField(\"impact\", StringType(), True),\n",
    "    StructField(\"priority\", StringType(), True),\n",
    "    StructField(\"sla_status\", StringType(), True),\n",
    "    StructField(\"budget_hours\", StringType(), True),\n",
    "    StructField(\"opportunity\", StringType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"vcio\", StringType(), True),\n",
    "    StructField(\"account_tech\", StringType(), True),\n",
    "    StructField(\"assigned_by\", StringType(), True),\n",
    "    StructField(\"closed_by\", StringType(), True),\n",
    "    StructField(\"closed_date\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load JSON file with the schema\n",
    "json_file_path = \"staging-bucket/tickets.json\"  # Replace with your file path\n",
    "json_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(json_file_path)\n",
    "\n",
    "# Display schema and data\n",
    "json_df.printSchema()\n",
    "json_df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df434627-5c80-4564-9925-ab01bfdf3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directly into the Iceberg table\n",
    "json_df.writeTo(\"iceberg_data.cb_di.tickets_stg\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf796187-1bf8-467f-b003-f7759d1ab0d5",
   "metadata": {},
   "source": [
    "### 3/5. Ingest data from file \"time_entries.json\" to table \"iceberg_data.cb_di.time_entries_stg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97b13ae9-7043-4352-a079-5985cfa48666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "|identifier|user                                   |hours              |date|billable|work_role|status|location|business_unit|agreement|agreement_type|invoice_number|start_time|end_time|return_type|\n",
      "+----------+---------------------------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "|1160693   |csalter                                |0.31666666666666665|null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|1160715   |asheikh                                |0.5                |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|1160197   |Leah Katsos lkatsos@proexpt.com (email)|0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|1160679   |koechsle                               |0.25               |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|1160684   |jhill                                  |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|250236    |mclark                                 |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|250660    |dwoltjen                               |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|250588    |CReynolds                              |1.25               |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|250588    |dwoltjen                               |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|252632    |JLevine                                |0.5                |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|252632    |JLevine                                |0.16666666666666666|null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|252826    |LCiulla                                |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961520    |RRogers                                |0.2833333333333333 |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961527    |Tsilva                                 |0.43333333333333335|null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961527    |jwilliams                              |1.3333333333333333 |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961527    |Tsilva                                 |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961530    |vgallucci                              |0.05               |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961544    |adelmonaco                             |0                  |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961538    |Tsilva                                 |2.25               |null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "|961538    |Tsilva                                 |0.36666666666666664|null|        |         |      |        |             |         |              |              |null      |null    |CwTicket   |\n",
      "+----------+---------------------------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "\n",
    "# Define schema with all columns as StringType\n",
    "schema = StructType([\n",
    "    StructField(\"identifier\", StringType(), True),\n",
    "    StructField(\"user\", StringType(), True),\n",
    "    StructField(\"hours\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"billable\", StringType(), True),\n",
    "    StructField(\"work_role\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"business_unit\", StringType(), True),\n",
    "    StructField(\"agreement\", StringType(), True),\n",
    "    StructField(\"agreement_type\", StringType(), True),\n",
    "    StructField(\"invoice_number\", StringType(), True),\n",
    "    StructField(\"start_time\", StringType(), True),\n",
    "    StructField(\"end_time\", StringType(), True),\n",
    "    StructField(\"return_type\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = \"staging-bucket/time_entries.json\"  # Replace with your actual path\n",
    "\n",
    "# Read JSON file using the defined schema\n",
    "json_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(json_file_path)\n",
    "\n",
    "# Show the data\n",
    "json_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de8aced2-1453-4dc5-ba8b-3b873fed731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directly into the Iceberg table\n",
    "json_df.writeTo(\"iceberg_data.cb_di.time_entries_stg\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23813d-8d71-4d2f-8f5f-e827b2ee2d50",
   "metadata": {},
   "source": [
    "### 4/5. Ingest data from file \"configs.json\" to table \"iceberg_data.cb_di.configs_stg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3038c46-d427-4733-8904-7f6b163abf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------------+------------+--------------+------------+----------+--------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+------------------------------------+------------+----------------------------------------+----------------------------------------------------------------------------------+\n",
      "|identifier|link                                                                                                                                                 |integration_type|updated_date        |updated_by  |integration_id|parent_name |company_id|created_date        |created_by  |return_type|business_unit_id|business_unit|location_id|location|config_type|status   |SLA |install_date|installed_by|purchase_date|expiration_date|vendor|manufacturer|part_number|model_number    |serial_number  |tag_number|bill_customer|needs_renewal|contact|site                                |site_address|notes                                   |vendor_notes                                                                      |\n",
      "+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------------+------------+--------------+------------+----------+--------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+------------------------------------+------------+----------------------------------------+----------------------------------------------------------------------------------+\n",
      "|16707     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=16707&companyName=training|ConnectWise     |2021-04-28T10:15:04Z|mportillo   |877           |Teldar Paper|312       |2021-04-28T10:14:50Z|mportillo   |CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | MYL92LL/A      | H97FD1GLQ1GC  |          |null         |null         |null   | North Riverdale                    |null        | with AppleCare+ ends Thu 04/20/2023    |                                                                                  |\n",
      "|16719     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=16719&companyName=training|ConnectWise     |2021-04-29T14:55:51Z|ccalmeiro   |877           |Teldar Paper|312       |2021-04-29T14:55:51Z|ccalmeiro   |CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | MR33           | Q2PD-3U2B-92V2|          |null         |null         |null   | North Riverdale                    |null        |                                        |                                                                                  |\n",
      "|16717     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=16717&companyName=training|ConnectWise     |2021-04-29T14:34:31Z|ccalmeiro   |877           |Teldar Paper|312       |2021-04-29T14:34:31Z|ccalmeiro   |CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | MX65           | Q2QN-GJNB-EHY5|          |null         |null         |null   | North Riverdale                    |null        |                                        |                                                                                  |\n",
      "|16702     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=16702&companyName=training|ConnectWise     |2021-04-28T10:13:33Z|mportillo   |877           |Teldar Paper|312       |2021-04-28T10:05:38Z|mportillo   |CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | MYL92LL/A      | H97FD0XNQ1GC  |          |null         |null         |null   | Massapequa                         |null        | with AppleCare+ ends Thu 04/20/2023    |                                                                                  |\n",
      "|16718     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=16718&companyName=training|ConnectWise     |2021-04-29T14:36:27Z|ccalmeiro   |877           |Teldar Paper|312       |2021-04-29T14:36:27Z|ccalmeiro   |CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | MS120-24P      | Q2EX-NMES-P3T2|          |null         |null         |null   | North Riverdale                    |null        |                                        |                                                                                  |\n",
      "|11464     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11464&companyName=training|ConnectWise     |2017-06-02T12:25:46Z|NManganiello|877           |Teldar Paper|312       |2017-06-02T12:25:28Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | SG300-52P      | PSZ21031UFH   |          |null         |null         |null   | ProEx - Stratham                   |null        | - SSH/HTTPS enabled from management IP.|                                                                                  |\n",
      "|11386     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11386&companyName=training|ConnectWise     |2020-09-14T20:32:50Z|RRogers     |877           |Teldar Paper|312       |2017-05-31T15:45:48Z|JFernandez  |CwConfig   |29              |null         |65         |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       |                |               |          |null         |null         |null   | Summit                             |null        | Verizon phone lines                    |                                                                                  |\n",
      "|11388     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11388&companyName=training|ConnectWise     |2020-06-23T21:27:31Z|dortiz      |877           |Teldar Paper|312       |2017-06-01T14:29:38Z|DPellegrino |CwConfig   |16              |null         |2          |null    |null       | Inactive|null|null        |null        |null         |null           |null  |null        |null       | 5505ASA        | JMX192140JQ   |          |null         |null         |null   | NOT IN PRODUCTION                  |null        |                                        |                                                                                  |\n",
      "|11394     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11394&companyName=training|ConnectWise     |2019-01-07T15:29:27Z|mmcdonald   |877           |Teldar Paper|312       |2017-06-01T18:10:21Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       |                |               |          |null         |null         |null   | ProEx - Financial District - Boston|null        | ISP Circuit                            |                                                                                  |\n",
      "|11402     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11402&companyName=training|ConnectWise     |2017-06-01T18:23:35Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T18:23:12Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | LaserJet M252dw|               |          |null         |null         |null   | ProEx - Government Center - Boston |null        | - Located on the back desk             |                                                                                  |\n",
      "|11410     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11410&companyName=training|ConnectWise     |2018-09-19T15:55:57Z|ccalmeiro   |877           |Teldar Paper|312       |2017-06-01T18:33:59Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | XM1145         | 70155PHH0YWMY |          |null         |null         |null   | ProEx - Haverhill/Bradford         |null        | - Located at the front desk            |                                                                                  |\n",
      "|11416     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11416&companyName=training|ConnectWise     |2017-06-01T18:52:44Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T18:46:57Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | LaserJet M252dw|               |          |null         |null         |null   | ProEx - Haverhill/Dudley Plaza     |null        |                                        |                                                                                  |\n",
      "|11406     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11406&companyName=training|ConnectWise     |2017-06-01T18:30:09Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T18:30:09Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | SG300-28P      | DNI203601LZ   |          |null         |null         |null   | ProEx - Haverhill/Bradford         |null        | - SSH/HTTPS enabled from management IP.|                                                                                  |\n",
      "|11422     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11422&companyName=training|ConnectWise     |2017-06-01T20:20:16Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:20:16Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | Meraki MR33    | Q2PD-PX7U-BLZ7|          |null         |null         |null   | ProEx - Middleton                  |null        | - Managed in Cisco Meraki Dashboard    |                                                                                  |\n",
      "|11428     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11428&companyName=training|ConnectWise     |2017-06-01T20:27:39Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:27:39Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | Meraki MX65    | Q2QN-MR8E-5MLP|          |null         |null         |null   | ProEx - North Andover              |null        | - Managed in Cisco Meraki Dashboard    |                                                                                  |\n",
      "|11414     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11414&companyName=training|ConnectWise     |2018-09-27T13:52:37Z|mmcdonald   |877           |Teldar Paper|312       |2017-06-01T18:43:57Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       |                |               |          |null         |null         |null   | ProEx - Haverhill/Dudley Plaza     |null        | ISP Circuit                            | - As of 6/1/2017, this circuit is currently double-NAT&#39;d behind an ISP router|\n",
      "|11418     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11418&companyName=training|ConnectWise     |2017-06-01T20:15:18Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:15:18Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       |                |               |          |null         |null         |null   | ProEx - Haverhill/Dudley Plaza     |null        | - See documents tab for attached photos|                                                                                  |\n",
      "|11432     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11432&companyName=training|ConnectWise     |2017-06-01T20:31:17Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:31:17Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | LaserJet M252dw|               |          |null         |null         |null   | ProEx - North Andover              |null        | - Located in the front office          |                                                                                  |\n",
      "|11438     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11438&companyName=training|ConnectWise     |2017-06-01T20:37:11Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:37:11Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | Meraki MR33    | Q2PD-GRVC-74MX|          |null         |null         |null   | ProEx - Salem                      |null        | - Managed in Cisco Meraki Dashboard    |                                                                                  |\n",
      "|11436     |https://connect.chipstechnologygroup.com/v4_6_release/services/system_io/router/openrecord.rails?recordType=ConfigFV&recid=11436&companyName=training|ConnectWise     |2017-06-01T20:35:42Z|NManganiello|877           |Teldar Paper|312       |2017-06-01T20:35:40Z|NManganiello|CwConfig   |10              |null         |2          |null    |null       | Active  |null|null        |null        |null         |null           |null  |null        |null       | SG300-28P      | DNI203602K6   |          |null         |null         |null   | ProEx - Salem                      |null        | - SSH/HTTPS enabled from management IP.|                                                                                  |\n",
      "+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------+----------------+--------------------+------------+--------------+------------+----------+--------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+------------------------------------+------------+----------------------------------------+----------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "# Define schema with all columns as StringType (VARCHAR equivalent)\n",
    "schema = StructType([\n",
    "    StructField(\"identifier\", StringType(), True),\n",
    "    StructField(\"link\", StringType(), True),\n",
    "    StructField(\"integration_type\", StringType(), True),\n",
    "    StructField(\"updated_date\", StringType(), True),\n",
    "    StructField(\"updated_by\", StringType(), True),\n",
    "    StructField(\"integration_id\", StringType(), True),\n",
    "    StructField(\"parent_name\", StringType(), True),\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"created_date\", StringType(), True),\n",
    "    StructField(\"created_by\", StringType(), True),\n",
    "    StructField(\"return_type\", StringType(), True),\n",
    "    StructField(\"business_unit_id\", StringType(), True),\n",
    "    StructField(\"business_unit\", StringType(), True),\n",
    "    StructField(\"location_id\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"config_type\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"SLA\", StringType(), True),\n",
    "    StructField(\"install_date\", StringType(), True),\n",
    "    StructField(\"installed_by\", StringType(), True),\n",
    "    StructField(\"purchase_date\", StringType(), True),\n",
    "    StructField(\"expiration_date\", StringType(), True),\n",
    "    StructField(\"vendor\", StringType(), True),\n",
    "    StructField(\"manufacturer\", StringType(), True),\n",
    "    StructField(\"part_number\", StringType(), True),\n",
    "    StructField(\"model_number\", StringType(), True),\n",
    "    StructField(\"serial_number\", StringType(), True),\n",
    "    StructField(\"tag_number\", StringType(), True),\n",
    "    StructField(\"bill_customer\", StringType(), True),\n",
    "    StructField(\"needs_renewal\", StringType(), True),\n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"site\", StringType(), True),\n",
    "    StructField(\"site_address\", StringType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"vendor_notes\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load JSON data\n",
    "json_file_path = \"staging-bucket/configs.json\"  # Replace with actual path\n",
    "json_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(json_file_path)\n",
    "\n",
    "# Optional: Show the data\n",
    "json_df.show(truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e27673d-c3d7-4982-8614-ea11cfe2d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directly into the Iceberg table\n",
    "json_df.writeTo(\"iceberg_data.cb_di.configs_stg\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f301b4-c7a4-4d6b-98f4-552029a0a3a7",
   "metadata": {},
   "source": [
    "### 5/5. Ingest data from file \"contacts.json\" to table \"iceberg_data.cb_di.contacts_stg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdd3dc-1046-4375-9102-ba3fcdf453d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define the schema with StringType for all columns\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"link\", StringType(), True),\n",
    "    StructField(\"integration_type\", StringType(), True),\n",
    "    StructField(\"business_unit_id\", StringType(), True),\n",
    "    StructField(\"location_id\", StringType(), True),\n",
    "    StructField(\"identifier\", StringType(), True),\n",
    "    StructField(\"updated_date\", StringType(), True),\n",
    "    StructField(\"updated_by\", StringType(), True),\n",
    "    StructField(\"integration_id\", StringType(), True),\n",
    "    StructField(\"parent_name\", StringType(), True),\n",
    "    StructField(\"company_id\", StringType(), True),\n",
    "    StructField(\"created_date\", StringType(), True),\n",
    "    StructField(\"created_by\", StringType(), True),\n",
    "    StructField(\"return_type\", StringType(), True),\n",
    "    StructField(\"full_name\", StringType(), True),\n",
    "    StructField(\"company_location\", StringType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"site\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"phone_number\", StringType(), True),\n",
    "    StructField(\"facebook\", StringType(), True),\n",
    "    StructField(\"twitter\", StringType(), True),\n",
    "    StructField(\"linkedin\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load JSON file with the schema\n",
    "json_file_path = \"staging-bucket/contacts.json\"  # Replace with your file path\n",
    "json_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(json_file_path)\n",
    "\n",
    "# Display schema and data\n",
    "json_df.printSchema()\n",
    "json_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20100384-ff78-4432-b575-5a78396ef736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert directly into the Iceberg table\n",
    "json_df.writeTo(\"iceberg_data.cb_di.contacts_stg\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d752a81-0a9f-4dd2-8c50-63d1b6347e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea52b1c8-8b8d-456d-aeaf-c048f5e644ca",
   "metadata": {},
   "source": [
    "# Data Load from STG to Data Store tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653f3d2-665c-4566-a895-1702db749655",
   "metadata": {},
   "source": [
    "### 1/5 Data load from \"iceberg_data.cb_di.config_udfs_stg\" to \"iceberg_data.cb_di.config_udfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f0c4780-f0d9-44e7-9012-b8aea0571736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records from the config_udfs target table:\n",
      "+----------+----+-----+-----------+\n",
      "|identifier| key|value|return_type|\n",
      "+----------+----+-----+-----------+\n",
      "|     16707|null| null|   CwConfig|\n",
      "|     16719|null| null|   CwConfig|\n",
      "|     16717|null| null|   CwConfig|\n",
      "|     16702|null| null|   CwConfig|\n",
      "|     16718|null| null|   CwConfig|\n",
      "|     11464|null| null|   CwConfig|\n",
      "|     11386|null| null|   CwConfig|\n",
      "|     11388|null| null|   CwConfig|\n",
      "|     11394|null| null|   CwConfig|\n",
      "|     11402|null| null|   CwConfig|\n",
      "+----------+----+-----+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Source record count: 50, Target record count: 50\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the source DataFrame (assuming the source table is named 'config_udfs_stg')\n",
    "config_udfs_stg_df = spark.table(\"iceberg_data.cb_di.config_udfs_stg\")\n",
    "\n",
    "# Apply type conversions for each column\n",
    "converted_config_udfs_df = config_udfs_stg_df.select(\n",
    "    F.col(\"identifier\").cast(\"int\").alias(\"identifier\"),  # Convert to INT\n",
    "    F.col(\"key\").cast(\"string\").alias(\"key\"),  # Convert to STRING\n",
    "    F.col(\"value\").cast(\"string\").alias(\"value\"),  # Convert to STRING\n",
    "    F.col(\"return_type\").cast(\"string\").alias(\"return_type\")  # Convert to STRING\n",
    ")\n",
    "\n",
    "# Insert the transformed data into the target Iceberg table 'iceberg_data.cb_di.config_udfs'\n",
    "converted_config_udfs_df.write.format(\"iceberg\").mode(\"append\").insertInto(\"iceberg_data.cb_di.config_udfs\")\n",
    "\n",
    "# ---------------- Validation Section ----------------\n",
    "\n",
    "# Load the target table for validation\n",
    "target_config_udfs_df = spark.table(\"iceberg_data.cb_di.config_udfs\")\n",
    "\n",
    "# 1. Display a sample of records\n",
    "print(\"Sample records from the config_udfs target table:\")\n",
    "target_config_udfs_df.show(10)\n",
    "\n",
    "# 2. Count and compare the number of records\n",
    "source_count = config_udfs_stg_df.count()\n",
    "target_count = target_config_udfs_df.count()\n",
    "print(f\"Source record count: {source_count}, Target record count: {target_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ba9a5-40d1-4ef8-b77d-2822311bba5c",
   "metadata": {},
   "source": [
    "### 2/5 Data load from \"iceberg_data.cb_di.tickets_stg\" to \"iceberg_data.cb_di.tickets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247360c2-353e-4594-9d55-b1d0b948f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the source DataFrame (ticket_stg)\n",
    "ticket_stg_df = spark.table(\"iceberg_data.cb_di.tickets_stg\")\n",
    "#ticket_stg_df.show()\n",
    "# Apply necessary transformations, setting other columns to NULL or blank (\"\" for string columns)\n",
    "transformed_df = ticket_stg_df.select(\n",
    "    # Ensure the identifier is treated as a BIGINT\n",
    "    F.col(\"identifier\").cast(\"long\").alias(\"identifier\"),\n",
    "    \n",
    "    # Cast string fields to VARCHAR(255) as per the target schema\n",
    "    F.col(\"link\").cast(\"string\").alias(\"link\"),\n",
    "    F.col(\"integration_type\").cast(\"string\").alias(\"integration_type\"),\n",
    "    F.col(\"board_id\").cast(\"int\").alias(\"board_id\"),\n",
    "    F.col(\"board_name\").cast(\"string\").alias(\"board_name\"),\n",
    "    F.col(\"status_id\").cast(\"int\").alias(\"status_id\"),\n",
    "    F.col(\"status_name\").cast(\"string\").alias(\"status_name\"),\n",
    "    \n",
    "    # Cast actual_hours as FLOAT\n",
    "    F.col(\"actual_hours\").cast(\"float\").alias(\"actual_hours\"),\n",
    "    \n",
    "    # Cast concept as string\n",
    "    F.col(\"concept\").cast(\"string\").alias(\"concept\"),\n",
    "    \n",
    "    # Convert updated_date to TIMESTAMP as per the format specified\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(updated_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"updated_date\"),\n",
    "    \n",
    "    # Cast other string fields, set remaining to NULL\n",
    "    F.col(\"updated_by\").cast(\"string\").alias(\"updated_by\"),\n",
    "    F.col(\"integration_id\").cast(\"int\").alias(\"integration_id\"),\n",
    "    F.col(\"parent_name\").cast(\"string\").alias(\"parent_name\"),\n",
    "    F.col(\"company_id\").cast(\"int\").alias(\"company_id\"),\n",
    "    \n",
    "    # Convert created_date to TIMESTAMP\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(created_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"created_date\"),\n",
    "    \n",
    "    # Cast created_by as string\n",
    "    F.col(\"created_by\").cast(\"string\").alias(\"created_by\"),\n",
    "    \n",
    "    # Return_type, Type, Sub_type as string\n",
    "    F.col(\"return_type\").cast(\"string\").alias(\"return_type\"),\n",
    "    F.col(\"type\").cast(\"string\").alias(\"type\"),\n",
    "    F.col(\"sub_type\").cast(\"string\").alias(\"sub_type\"),\n",
    "    \n",
    "    # Other string fields (set to NULL if not in the source)\n",
    "    F.lit(None).cast(\"string\").alias(\"item\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"ticket_owner\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"sla\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"agreement\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"predecessor\"),  # Setting as NULL\n",
    "    \n",
    "    # Cast dates, or set NULL if not available\n",
    "    F.lit(None).cast(\"date\").alias(\"estimated_start_date\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"date\").alias(\"due_date\"),  # Setting as NULL\n",
    "    \n",
    "    # Cast duration as BIGINT (if not available, set NULL)\n",
    "    F.lit(None).cast(\"long\").alias(\"duration\"),  # Setting as NULL\n",
    "    \n",
    "    # Impact, priority, sla_status as string, setting NULL where needed\n",
    "    F.lit(None).cast(\"string\").alias(\"impact\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"priority\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"sla_status\"),  # Setting as NULL\n",
    "    \n",
    "    # Budget hours as FLOAT (set NULL)\n",
    "    F.lit(None).cast(\"float\").alias(\"budget_hours\"),  # Setting as NULL\n",
    "    \n",
    "    # Opportunity, source, vcio, account_tech, assigned_by, closed_by as string\n",
    "    F.lit(None).cast(\"string\").alias(\"opportunity\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"source\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"vcio\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"account_tech\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"assigned_by\"),  # Setting as NULL\n",
    "    F.lit(None).cast(\"string\").alias(\"closed_by\"),  # Setting as NULL\n",
    "    \n",
    "    # Convert closed_date to TIMESTAMP (set NULL if missing)\n",
    "    F.lit(None).cast(\"timestamp\").alias(\"closed_date\")  # Setting as NULL\n",
    ")\n",
    "#transformed_df.show()\n",
    "# Insert the transformed data into the target Iceberg table 'iceberg_data.cb_di.ticket'\n",
    "transformed_df.write.format(\"iceberg\").mode(\"overwrite\").insertInto(\"iceberg_data.cb_di.tickets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f172f-8e73-4114-8d47-ebf78f01ae63",
   "metadata": {},
   "source": [
    "### 3/5 Data load from \"iceberg_data.cb_di.time_entries_stg\" to \"iceberg_data.cb_di.time_entries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509e1789-c079-4111-8ce4-c23823558b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records from the time_entries target table:\n",
      "+----------+--------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "|identifier|                user|              hours|date|billable|work_role|status|location|business_unit|agreement|agreement_type|invoice_number|start_time|end_time|return_type|\n",
      "+----------+--------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "|   1160693|             csalter|0.31666666666666665|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|   1160715|             asheikh|                0.5|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|   1160197|Leah Katsos lkats...|                0.0|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|   1160679|            koechsle|               0.25|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|   1160684|               jhill|                0.0|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|    250236|              mclark|                0.0|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|    250660|            dwoltjen|                0.0|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|    250588|           CReynolds|               1.25|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|    250588|            dwoltjen|                0.0|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "|    252632|             JLevine|                0.5|null|    null|         |      |        |             |         |              |              |      null|    null|   CwTicket|\n",
      "+----------+--------------------+-------------------+----+--------+---------+------+--------+-------------+---------+--------------+--------------+----------+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Source record count: 58, Target record count: 58\n",
      "Schema of the target time_entries table:\n",
      "root\n",
      " |-- identifier: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- hours: double (nullable = true)\n",
      " |-- date: timestamp_ntz (nullable = true)\n",
      " |-- billable: boolean (nullable = true)\n",
      " |-- work_role: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- business_unit: string (nullable = true)\n",
      " |-- agreement: string (nullable = true)\n",
      " |-- agreement_type: string (nullable = true)\n",
      " |-- invoice_number: string (nullable = true)\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- end_time: string (nullable = true)\n",
      " |-- return_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the source DataFrame (assuming the source table is named 'time_entries_stg')\n",
    "time_entries_stg_df = spark.table(\"iceberg_data.cb_di.time_entries_stg\")\n",
    "\n",
    "# Apply type conversions for each column\n",
    "converted_time_entries_df = time_entries_stg_df.select(\n",
    "    F.col(\"identifier\").cast(\"int\").alias(\"identifier\"),  # Convert to INT\n",
    "    F.col(\"user\").cast(\"string\").alias(\"user\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"hours\").cast(\"double\").alias(\"hours\"),  # Convert to DOUBLE\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"date\"),  # Convert to TIMESTAMP\n",
    "    F.col(\"billable\").cast(\"boolean\").alias(\"billable\"),  # Convert to BOOLEAN\n",
    "    F.col(\"work_role\").cast(\"string\").alias(\"work_role\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"status\").cast(\"string\").alias(\"status\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"location\").cast(\"string\").alias(\"location\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"business_unit\").cast(\"string\").alias(\"business_unit\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"agreement\").cast(\"string\").alias(\"agreement\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"agreement_type\").cast(\"string\").alias(\"agreement_type\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"invoice_number\").cast(\"string\").alias(\"invoice_number\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"start_time\").cast(\"string\").alias(\"start_time\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"end_time\").cast(\"string\").alias(\"end_time\"),  # Convert to VARCHAR(255)\n",
    "    F.col(\"return_type\").cast(\"string\").alias(\"return_type\")  # Convert to VARCHAR(255)\n",
    ")\n",
    "\n",
    "# Insert the transformed data into the target Iceberg table 'iceberg_data.cb_di.time_entries'\n",
    "converted_time_entries_df.write.format(\"iceberg\").mode(\"overwrite\").insertInto(\"iceberg_data.cb_di.time_entries\")\n",
    "\n",
    "# ---------------- Validation Section ----------------\n",
    "\n",
    "# Load the target table for validation\n",
    "target_time_entries_df = spark.table(\"iceberg_data.cb_di.time_entries\")\n",
    "\n",
    "# 1. Display a sample of records\n",
    "print(\"Sample records from the time_entries target table:\")\n",
    "target_time_entries_df.show(10)\n",
    "\n",
    "# 2. Count and compare the number of records\n",
    "source_count = time_entries_stg_df.count()\n",
    "target_count = target_time_entries_df.count()\n",
    "print(f\"Source record count: {source_count}, Target record count: {target_count}\")\n",
    "\n",
    "# 3. Check schema consistency\n",
    "print(\"Schema of the target time_entries table:\")\n",
    "target_time_entries_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbcca53-a8ed-4db8-8a31-5a5e925c5711",
   "metadata": {},
   "source": [
    "### 4/5 Data load from \"iceberg_data.cb_di.configs_stg\" to \"iceberg_data.cb_di.configs_stg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9beaa02-c91a-45fc-bd16-a972efd5005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records from the configs target table:\n",
      "+----------+--------------------+----------------+-------------------+------------+--------------+------------+----------+-------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+--------------------+------------+--------------------+------------+\n",
      "|identifier|                link|integration_type|       updated_date|  updated_by|integration_id| parent_name|company_id|       created_date|  created_by|return_type|business_unit_id|business_unit|location_id|location|config_type|   status| sla|install_date|installed_by|purchase_date|expiration_date|vendor|manufacturer|part_number|    model_number|  serial_number|tag_number|bill_customer|needs_renewal|contact|                site|site_address|               notes|vendor_notes|\n",
      "+----------+--------------------+----------------+-------------------+------------+--------------+------------+----------+-------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+--------------------+------------+--------------------+------------+\n",
      "|     16707|https://connect.c...|     ConnectWise|2021-04-28 06:15:04|   mportillo|           877|Teldar Paper|       312|2021-04-28 06:14:50|   mportillo|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|       MYL92LL/A|   H97FD1GLQ1GC|          |         null|         null|   null|     North Riverdale|        null| with AppleCare+ ...|            |\n",
      "|     16719|https://connect.c...|     ConnectWise|2021-04-29 10:55:51|   ccalmeiro|           877|Teldar Paper|       312|2021-04-29 10:55:51|   ccalmeiro|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|            MR33| Q2PD-3U2B-92V2|          |         null|         null|   null|     North Riverdale|        null|                    |            |\n",
      "|     16717|https://connect.c...|     ConnectWise|2021-04-29 10:34:31|   ccalmeiro|           877|Teldar Paper|       312|2021-04-29 10:34:31|   ccalmeiro|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|            MX65| Q2QN-GJNB-EHY5|          |         null|         null|   null|     North Riverdale|        null|                    |            |\n",
      "|     16702|https://connect.c...|     ConnectWise|2021-04-28 06:13:33|   mportillo|           877|Teldar Paper|       312|2021-04-28 06:05:38|   mportillo|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|       MYL92LL/A|   H97FD0XNQ1GC|          |         null|         null|   null|          Massapequa|        null| with AppleCare+ ...|            |\n",
      "|     16718|https://connect.c...|     ConnectWise|2021-04-29 10:36:27|   ccalmeiro|           877|Teldar Paper|       312|2021-04-29 10:36:27|   ccalmeiro|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|       MS120-24P| Q2EX-NMES-P3T2|          |         null|         null|   null|     North Riverdale|        null|                    |            |\n",
      "|     11464|https://connect.c...|     ConnectWise|2017-06-02 08:25:46|NManganiello|           877|Teldar Paper|       312|2017-06-02 08:25:28|NManganiello|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|       SG300-52P|    PSZ21031UFH|          |         null|         null|   null|    ProEx - Stratham|        null| - SSH/HTTPS enab...|            |\n",
      "|     11386|https://connect.c...|     ConnectWise|2020-09-14 16:32:50|     RRogers|           877|Teldar Paper|       312|2017-05-31 11:45:48|  JFernandez|   CwConfig|              29|         null|         65|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|                |               |          |         null|         null|   null|              Summit|        null| Verizon phone lines|            |\n",
      "|     11388|https://connect.c...|     ConnectWise|2020-06-23 17:27:31|      dortiz|           877|Teldar Paper|       312|2017-06-01 10:29:38| DPellegrino|   CwConfig|              16|         null|          2|    null|       null| Inactive|null|        null|        null|         null|           null|  null|        null|       null|         5505ASA|    JMX192140JQ|          |         null|         null|   null|   NOT IN PRODUCTION|        null|                    |            |\n",
      "|     11394|https://connect.c...|     ConnectWise|2019-01-07 10:29:27|   mmcdonald|           877|Teldar Paper|       312|2017-06-01 14:10:21|NManganiello|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null|                |               |          |         null|         null|   null| ProEx - Financia...|        null|         ISP Circuit|            |\n",
      "|     11402|https://connect.c...|     ConnectWise|2017-06-01 14:23:35|NManganiello|           877|Teldar Paper|       312|2017-06-01 14:23:12|NManganiello|   CwConfig|              10|         null|          2|    null|       null|   Active|null|        null|        null|         null|           null|  null|        null|       null| LaserJet M252dw|               |          |         null|         null|   null| ProEx - Governme...|        null| - Located on the...|            |\n",
      "+----------+--------------------+----------------+-------------------+------------+--------------+------------+----------+-------------------+------------+-----------+----------------+-------------+-----------+--------+-----------+---------+----+------------+------------+-------------+---------------+------+------------+-----------+----------------+---------------+----------+-------------+-------------+-------+--------------------+------------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Source record count: 50, Target record count: 50\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the source DataFrame (assuming the source table is named 'configs_stg')\n",
    "configs_stg_df = spark.table(\"iceberg_data.cb_di.configs_stg\")\n",
    "\n",
    "# Apply type conversions for each column\n",
    "converted_configs_df = configs_stg_df.select(\n",
    "    F.col(\"identifier\").cast(\"int\").alias(\"identifier\"),\n",
    "    F.col(\"link\").cast(\"string\").alias(\"link\"),\n",
    "    F.col(\"integration_type\").cast(\"string\").alias(\"integration_type\"),\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(updated_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"updated_date\"),\n",
    "    F.col(\"updated_by\").cast(\"string\").alias(\"updated_by\"),\n",
    "    F.col(\"integration_id\").cast(\"int\").alias(\"integration_id\"),\n",
    "    F.col(\"parent_name\").cast(\"string\").alias(\"parent_name\"),\n",
    "    F.col(\"company_id\").cast(\"int\").alias(\"company_id\"),\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(created_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"created_date\"),\n",
    "    F.col(\"created_by\").cast(\"string\").alias(\"created_by\"),\n",
    "    F.col(\"return_type\").cast(\"string\").alias(\"return_type\"),\n",
    "    F.col(\"business_unit_id\").cast(\"int\").alias(\"business_unit_id\"),\n",
    "    F.col(\"business_unit\").cast(\"string\").alias(\"business_unit\"),\n",
    "    F.col(\"location_id\").cast(\"int\").alias(\"location_id\"),\n",
    "    F.col(\"location\").cast(\"string\").alias(\"location\"),\n",
    "    F.col(\"config_type\").cast(\"string\").alias(\"config_type\"),\n",
    "    F.col(\"status\").cast(\"string\").alias(\"status\"),\n",
    "    F.col(\"SLA\").cast(\"string\").alias(\"SLA\"),\n",
    "    F.col(\"install_date\").cast(\"string\").alias(\"install_date\"),\n",
    "    F.col(\"installed_by\").cast(\"string\").alias(\"installed_by\"),\n",
    "    F.col(\"purchase_date\").cast(\"date\").alias(\"purchase_date\"),\n",
    "    F.col(\"expiration_date\").cast(\"date\").alias(\"expiration_date\"),\n",
    "    F.col(\"vendor\").cast(\"string\").alias(\"vendor\"),\n",
    "    F.col(\"manufacturer\").cast(\"string\").alias(\"manufacturer\"),\n",
    "    F.col(\"part_number\").cast(\"string\").alias(\"part_number\"),\n",
    "    F.col(\"model_number\").cast(\"string\").alias(\"model_number\"),\n",
    "    F.col(\"serial_number\").cast(\"string\").alias(\"serial_number\"),\n",
    "    F.col(\"tag_number\").cast(\"string\").alias(\"tag_number\"),\n",
    "    F.col(\"bill_customer\").cast(\"boolean\").alias(\"bill_customer\"),\n",
    "    F.col(\"needs_renewal\").cast(\"boolean\").alias(\"needs_renewal\"),\n",
    "    F.col(\"contact\").cast(\"string\").alias(\"contact\"),\n",
    "    F.col(\"site\").cast(\"string\").alias(\"site\"),\n",
    "    F.col(\"site_address\").cast(\"string\").alias(\"site_address\"),\n",
    "    F.col(\"notes\").cast(\"string\").alias(\"notes\"),\n",
    "    F.col(\"vendor_notes\").cast(\"string\").alias(\"vendor_notes\")\n",
    ")\n",
    "\n",
    "# Insert the transformed data into the target Iceberg table 'iceberg_data.cb_di.configs'\n",
    "converted_configs_df.write.format(\"iceberg\").mode(\"overwrite\").insertInto(\"iceberg_data.cb_di.configs\")\n",
    "\n",
    "# ---------------- Validation Section ----------------\n",
    "\n",
    "# Load the target table for validation\n",
    "target_configs_df = spark.table(\"iceberg_data.cb_di.configs\")\n",
    "\n",
    "# 1. Display a sample of records\n",
    "print(\"Sample records from the configs target table:\")\n",
    "target_configs_df.show(10)\n",
    "\n",
    "# 2. Count and compare the number of records\n",
    "source_count = configs_stg_df.count()\n",
    "target_count = target_configs_df.count()\n",
    "print(f\"Source record count: {source_count}, Target record count: {target_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2494a-b674-499d-b996-020e6035330f",
   "metadata": {},
   "source": [
    "### 5/5 Data load from \"iceberg_data.cb_di.contacts_stg\" to \"iceberg_data.cb_di.contacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b529649b-cea5-463e-a63b-d4bc19126a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample records from the contacts target table:\n",
      "+----+-----+--------------------+----------------+----------------+-----------+----------+-------------------+------------+--------------+-----------+----------+-------------------+-----------+-----------+----------------+----------------+----------+-----+-----+------------+--------+-------+--------+\n",
      "|  id|title|                link|integration_type|business_unit_id|location_id|identifier|       updated_date|  updated_by|integration_id|parent_name|company_id|       created_date| created_by|return_type|       full_name|company_location|department| site|email|phone_number|facebook|twitter|linkedin|\n",
      "+----+-----+--------------------+----------------+----------------+-----------+----------+-------------------+------------+--------------+-----------+----------+-------------------+-----------+-----------+----------------+----------------+----------+-----+-----+------------+--------+-------+--------+\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       377|2025-01-12 17:02:26| CrushbankQA|          1099|ConnectWise|       389|2025-01-12 17:02:26|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       376|2025-01-05 17:01:47| CrushbankQA|          1099|ConnectWise|       389|2025-01-05 17:01:47|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       375|2024-12-29 17:01:40| CrushbankQA|          1099|ConnectWise|       389|2024-12-29 17:01:40|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       374|2024-12-22 17:01:34| CrushbankQA|          1099|ConnectWise|       389|2024-12-22 17:01:34|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       373|2024-12-15 17:01:49| CrushbankQA|          1099|ConnectWise|       389|2024-12-15 17:01:49|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       372|2024-12-08 17:01:29| CrushbankQA|          1099|ConnectWise|       389|2024-12-08 17:01:29|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|              23|         38|       370|2024-11-13 05:15:16|      admin1|          1099| QA Company|       389|2024-11-13 05:15:16|     admin1|  CwContact|       Training |       Corporate|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       369|2024-08-25 18:01:30| CrushbankQA|          1099|ConnectWise|       389|2024-08-25 18:01:30|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       368|2024-08-18 18:01:35| CrushbankQA|          1099|ConnectWise|       389|2024-08-18 18:01:35|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "|null|     |https://staging.c...|     ConnectWise|               0|          2|       367|2024-08-11 18:01:51| CrushbankQA|          1099|ConnectWise|       389|2024-08-11 18:01:51|CrushbankQA|  CwContact| Automation test|    Tampa Office|          | Main| null|        null|        |       |        |\n",
      "+----+-----+--------------------+----------------+----------------+-----------+----------+-------------------+------------+--------------+-----------+----------+-------------------+-----------+-----------+----------------+----------------+----------+-----+-----+------------+--------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Source record count: 49, Target record count: 49\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load the source DataFrame (assuming the source table is named 'contacts_stg')\n",
    "contacts_stg_df = spark.table(\"iceberg_data.cb_di.contacts_stg\")\n",
    "\n",
    "# Apply type conversions for each column\n",
    "converted_contacts_df = contacts_stg_df.select(\n",
    "    F.col(\"id\").cast(\"long\").alias(\"id\"),  # Convert to BIGINT\n",
    "    F.col(\"title\").cast(\"string\").alias(\"title\"),  # Convert to VARCHAR\n",
    "    F.col(\"link\").cast(\"string\").alias(\"link\"),  # Convert to VARCHAR\n",
    "    F.col(\"integration_type\").cast(\"string\").alias(\"integration_type\"),  # Convert to VARCHAR\n",
    "    F.col(\"business_unit_id\").cast(\"int\").alias(\"business_unit_id\"),  # Convert to INT\n",
    "    F.col(\"location_id\").cast(\"int\").alias(\"location_id\"),  # Convert to INT\n",
    "    F.col(\"identifier\").cast(\"int\").alias(\"identifier\"),  # Convert to INT\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(updated_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"updated_date\"),  # Convert to TIMESTAMP\n",
    "    F.col(\"updated_by\").cast(\"string\").alias(\"updated_by\"),  # Convert to VARCHAR\n",
    "    F.col(\"integration_id\").cast(\"int\").alias(\"integration_id\"),  # Convert to INT\n",
    "    F.col(\"parent_name\").cast(\"string\").alias(\"parent_name\"),  # Convert to VARCHAR\n",
    "    F.col(\"company_id\").cast(\"int\").alias(\"company_id\"),  # Convert to INT\n",
    "    F.expr(\"CAST(REPLACE(REPLACE(created_date, 'T', ' '), 'Z', ' +00:00') AS TIMESTAMP)\").alias(\"created_date\"),  # Convert to TIMESTAMP\n",
    "    F.col(\"created_by\").cast(\"string\").alias(\"created_by\"),  # Convert to VARCHAR\n",
    "    F.col(\"return_type\").cast(\"string\").alias(\"return_type\"),  # Convert to VARCHAR\n",
    "    F.col(\"full_name\").cast(\"string\").alias(\"full_name\"),  # Convert to VARCHAR\n",
    "    F.col(\"company_location\").cast(\"string\").alias(\"company_location\"),  # Convert to VARCHAR\n",
    "    F.col(\"department\").cast(\"string\").alias(\"department\"),  # Convert to VARCHAR\n",
    "    F.col(\"site\").cast(\"string\").alias(\"site\"),  # Convert to VARCHAR\n",
    "    F.col(\"email\").cast(\"string\").alias(\"email\"),  # Convert to VARCHAR\n",
    "    F.col(\"phone_number\").cast(\"string\").alias(\"phone_number\"),  # Convert to VARCHAR\n",
    "    F.col(\"facebook\").cast(\"string\").alias(\"facebook\"),  # Convert to VARCHAR\n",
    "    F.col(\"twitter\").cast(\"string\").alias(\"twitter\"),  # Convert to VARCHAR\n",
    "    F.col(\"linkedin\").cast(\"string\").alias(\"linkedin\")  # Convert to VARCHAR\n",
    ")\n",
    "\n",
    "# Insert the transformed data into the target Iceberg table 'iceberg_data.cb_di.contacts'\n",
    "converted_contacts_df.write.format(\"iceberg\").mode(\"overwrite\").insertInto(\"iceberg_data.cb_di.contacts\")\n",
    "\n",
    "# ---------------- Validation Section ----------------\n",
    "\n",
    "# Load the target table for validation\n",
    "target_contacts_df = spark.table(\"iceberg_data.cb_di.contacts\")\n",
    "\n",
    "# 1. Display a sample of records\n",
    "print(\"Sample records from the contacts target table:\")\n",
    "target_contacts_df.show(10)\n",
    "\n",
    "# 2. Count and compare the number of records\n",
    "source_count = contacts_stg_df.count()\n",
    "target_count = target_contacts_df.count()\n",
    "print(f\"Source record count: {source_count}, Target record count: {target_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa5fcc-e9f8-44a7-a1c4-eff4b18f5b5c",
   "metadata": {},
   "source": [
    "# Data Ingestion is complete. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
